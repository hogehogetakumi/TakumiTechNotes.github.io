{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPQWWYUGSZjTcA5l4lLGYpQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hogehogetakumi/TakumiTechNotes.github.io/blob/main/test1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install -qU langchain langchain-community pypdf langchain-google-genai docx2txt faiss-cpu"
      ],
      "metadata": {
        "collapsed": true,
        "id": "klRgliybd3KZ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "from pathlib import Path\n",
        "from google.colab import userdata\n",
        "from langchain.schema import Document, HumanMessage, AIMessage\n",
        "from langchain.document_loaders import TextLoader, Docx2txtLoader\n",
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain_google_genai import GoogleGenerativeAIEmbeddings, ChatGoogleGenerativeAI\n",
        "from langchain.vectorstores import FAISS\n"
      ],
      "metadata": {
        "id": "SYYaEntseCab"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(doc: Document) -> Document:\n",
        "    text = doc.page_content\n",
        "    # ヘッダー／フッターの簡易除去\n",
        "    text = re.sub(r'第[一二三四五六七八九十]+章.*\\n', '', text)\n",
        "    text = re.sub(r'Copyright.*\\n', '', text)\n",
        "    text = re.sub(r'\\n\\s*\\n+', '\\n\\n', text)\n",
        "    text = re.sub(r'[ \\t]+', ' ', text)\n",
        "    text = re.sub(r'([^\\。\\?\\!])\\n([^\\n])', r'\\1\\2', text)\n",
        "    meta = {\n",
        "        'source': doc.metadata.get('source'),\n",
        "        'page': doc.metadata.get('page')\n",
        "    }\n",
        "    return Document(page_content=text.strip(), metadata=meta)"
      ],
      "metadata": {
        "id": "2YK3fSyneIQZ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_documents_from_folder(folder_path: str):\n",
        "    docs = []\n",
        "    for fname in os.listdir(folder_path):\n",
        "        path = Path(folder_path) / fname\n",
        "        if not path.is_file(): continue\n",
        "        try:\n",
        "            suffix = path.suffix.lower().lstrip('.')\n",
        "            if suffix == \"pdf\":\n",
        "                loader = PyPDFLoader(path)\n",
        "            elif suffix in (\"txt\", \"md\"):\n",
        "                loader = TextLoader(path, encoding=\"utf-8\")\n",
        "            elif suffix == \"docx\":\n",
        "                loader = Docx2txtLoader(path)\n",
        "            else:\n",
        "                print(f\"Skipping unsupported: {fname}\")\n",
        "                continue\n",
        "            docs.extend(loader.load())\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading {fname}: {e}\")\n",
        "    return docs"
      ],
      "metadata": {
        "id": "6ClsiMZleLjl"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rl2aP6JIdzUq",
        "outputId": "d8d2422f-9be6-4cee-a267-a4b74907b8a4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "あなた: exit\n",
            "会話を終了します。\n"
          ]
        }
      ],
      "source": [
        "def main():\n",
        "    # ─── 1. ドキュメント読み込み＆前処理 ───\n",
        "    raw_docs = load_documents_from_folder(\"data\")\n",
        "    clean_docs = [preprocess(d) for d in raw_docs]\n",
        "\n",
        "    # ─── 2. チャンク分割 ───\n",
        "    splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
        "    chunks = splitter.split_documents(clean_docs)\n",
        "\n",
        "    # ─── 3. 埋め込み＆ベクトルストア構築 ───\n",
        "    api_key = userdata.get(\"GEMINI_API_KEY\")\n",
        "    embeddings = GoogleGenerativeAIEmbeddings(\n",
        "        google_api_key=api_key,\n",
        "        model=\"models/embedding-001\"\n",
        "    )\n",
        "    vectorstore = FAISS.from_documents(chunks, embeddings)\n",
        "    retriever = vectorstore.as_retriever(search_kwargs={\"k\": 3})\n",
        "\n",
        "    # ─── 4. LLM 初期化 ───\n",
        "    llm = ChatGoogleGenerativeAI(\n",
        "        google_api_key=api_key,\n",
        "        model=\"gemini-2.5-flash\",\n",
        "        temperature=0\n",
        "    )\n",
        "\n",
        "    # 会話履歴は HumanMessage/AIMessage のリストで保持\n",
        "    conversation_history = []\n",
        "\n",
        "    # ─── 5. チャットループ ───\n",
        "    while True:\n",
        "        user_input = input(\"あなた: \")\n",
        "        if user_input.lower() in (\"\", \"exit\", \"quit\"):\n",
        "            print(\"会話を終了します。\")\n",
        "            break\n",
        "\n",
        "        # 履歴にユーザーメッセージを追加\n",
        "        conversation_history.append(HumanMessage(content=user_input))\n",
        "\n",
        "        # ─── 5-1. リトリーバル ───\n",
        "        docs = retriever.get_relevant_documents(user_input)\n",
        "        # メタ情報付きでまとめてプロンプトに含める\n",
        "        context = \"\\n\\n\".join(\n",
        "            f\"[{d.metadata['source']} p.{d.metadata['page']}]\\n{d.page_content}\"\n",
        "            for d in docs\n",
        "        )\n",
        "\n",
        "        # ─── 5-2. LLM 呼び出し ───\n",
        "        # ここでは、まず「ドキュメント参照指示」→ 会話履歴 → AI に渡します\n",
        "        messages = []\n",
        "        messages.append(HumanMessage(\n",
        "            content=f\"以下のドキュメントを参照して回答してください：\\n{context}\\n\\n質問: {user_input}\"\n",
        "        ))\n",
        "        # 過去の会話履歴も続けて渡す\n",
        "        messages.extend(conversation_history[:-1])  # 最新のユーザーメッセージは既に先頭に含めたので除外\n",
        "\n",
        "        # 実際の呼び出し\n",
        "        ai_message: AIMessage = llm(messages)\n",
        "        conversation_history.append(ai_message)\n",
        "\n",
        "        # ─── 5-3. 応答表示 ───\n",
        "        print(\"アシスタント:\", ai_message.content)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OsX4EBvqg6DP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}